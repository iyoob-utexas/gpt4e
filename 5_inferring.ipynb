{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOczC7XZjTdYiTLpSUXBQz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iyoob-utexas/gpt4e/blob/main/5_inferring.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inferring\n",
        "In this lesson, you will infer sentiment and topics from product reviews and news articles."
      ],
      "metadata": {
        "id": "-lUKdCsT_KP3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize"
      ],
      "metadata": {
        "id": "d5FoRirZkuy7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Install Libraries"
      ],
      "metadata": {
        "id": "zjhtaC-TAnqE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install openai\n",
        "!pip install colab-env -qU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-vYbupfkggT",
        "outputId": "1ee075b7-879f-4c6a-8c78-f8f609b7ea75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.0.1)\n",
            "Collecting pip\n",
            "  Downloading pip-23.1.2-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.0.1\n",
            "    Uninstalling pip-23.0.1:\n",
            "      Successfully uninstalled pip-23.0.1\n",
            "Successfully installed pip-23.1.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.6-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Collecting aiohttp (from openai)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->openai)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->openai)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->openai)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->openai)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.6 yarl-1.9.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for colab-env (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Load Creds"
      ],
      "metadata": {
        "id": "60iOOpLQAtZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import colab_env\n",
        "\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "y60lE09wiQZT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86b0d9e9-b335-4e57-ceff-0cc3820e245b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Helper Function"
      ],
      "metadata": {
        "id": "h5_kIN613laP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0, # this is the degree of randomness of the model's output\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]"
      ],
      "metadata": {
        "id": "lKzwJ9gX3j7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Product Review Text"
      ],
      "metadata": {
        "id": "6EhGpy7GBTI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lamp_review = \"\"\"\n",
        "Needed a nice lamp for my bedroom, and this one had \\\n",
        "additional storage and not too high of a price point. \\\n",
        "Got it fast.  The string to our lamp broke during the \\\n",
        "transit and the company happily sent over a new one. \\\n",
        "Came within a few days as well. It was easy to put \\\n",
        "together.  I had a missing part, so I contacted their \\\n",
        "support and they very quickly got me the missing piece! \\\n",
        "Lumina seems to me to be a great company that cares \\\n",
        "about their customers and products!!\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "JT8SZ-QdBZc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Infer Sentiment"
      ],
      "metadata": {
        "id": "UrH9ZeyxMVY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "What is the sentiment of the following product review, which is delimited with triple backticks?\n",
        "\n",
        "Review text: ```{lamp_review}```\n",
        "\"\"\"\n",
        "\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iyZZAcJCLsH",
        "outputId": "a67423d4-58f0-4f93-b8ba-6cc8cb66b82a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sentiment of the product review is positive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Infer Emotions"
      ],
      "metadata": {
        "id": "2cDcU_qEMdGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# multiple emotions\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Identify a list of emotions that the writer of the \\\n",
        "following review is expressing. Include no more than \\\n",
        "five items in the list. Format your answer as a list of \\\n",
        "lower-case words separated by commas.\n",
        "\n",
        "Review text: '''{lamp_review}'''\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "fTMpp-iUIYG_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98a1a97c-eb75-4c8c-aa2f-a9fdffbcc90c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "happy, satisfied, grateful, impressed, content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# specific emotion \n",
        "\n",
        "prompt = f\"\"\"\n",
        "Is the writer of the following review expressing anger?\\\n",
        "The review is delimited with triple backticks. \\\n",
        "Give your answer as either yes or no.\n",
        "\n",
        "Review text: '''{lamp_review}'''\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXspT2-SyBbs",
        "outputId": "bfc78424-74f1-49de-d086-6847f5f868bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Infer Entities"
      ],
      "metadata": {
        "id": "quGWdifHyJs0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# infer product and company name\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Identify the following items from the review text: \n",
        "- Item purchased by reviewer\n",
        "- Company that made the item\n",
        "\n",
        "The review is delimited with triple backticks. \\\n",
        "Format your response as a JSON object with \\\n",
        "\"Item\" and \"Brand\" as the keys. \n",
        "If the information isn't present, use \"unknown\" \\\n",
        "as the value.\n",
        "Make your response as short as possible.\n",
        "  \n",
        "Review text: '''{lamp_review}'''\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "iSkfCkccQEsX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e7be2ae-506c-47dd-d7af-4e040bddeab9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"Item\": \"lamp\",\n",
            "  \"Brand\": \"Lumina\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combine Inferences"
      ],
      "metadata": {
        "id": "AqccEHcKIS7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Identify the following items from the review text: \n",
        "- Sentiment (positive or negative)\n",
        "- Is the reviewer expressing anger? (true or false)\n",
        "- Item purchased by reviewer\n",
        "- Company that made the item\n",
        "\n",
        "The review is delimited with triple backticks. \\\n",
        "Format your response as a JSON object with \\\n",
        "\"Sentiment\", \"Anger\", \"Item\" and \"Brand\" as the keys.\n",
        "If the information isn't present, use \"unknown\" \\\n",
        "as the value.\n",
        "Make your response as short as possible.\n",
        "Format the Anger value as a boolean.\n",
        "\n",
        "Review text: '''{lamp_review}'''\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kK1CWwXlyy9z",
        "outputId": "055ee24b-eee5-492a-a73c-6629cde1b419"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"Sentiment\": \"positive\",\n",
            "  \"Anger\": false,\n",
            "  \"Item\": \"lamp with additional storage\",\n",
            "  \"Brand\": \"Lumina\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## News Article Text"
      ],
      "metadata": {
        "id": "HCJNQsvf0fH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "story = \"\"\"\n",
        "In a recent survey conducted by the government, \n",
        "public sector employees were asked to rate their level \n",
        "of satisfaction with the department they work at. \n",
        "The results revealed that NASA was the most popular \n",
        "department with a satisfaction rating of 95%.\n",
        "\n",
        "One NASA employee, John Smith, commented on the findings, \n",
        "stating, \"I'm not surprised that NASA came out on top. \n",
        "It's a great place to work with amazing people and \n",
        "incredible opportunities. I'm proud to be a part of \n",
        "such an innovative organization.\"\n",
        "\n",
        "The results were also welcomed by NASA's management team, \n",
        "with Director Tom Johnson stating, \"We are thrilled to \n",
        "hear that our employees are satisfied with their work at NASA. \n",
        "We have a talented and dedicated team who work tirelessly \n",
        "to achieve our goals, and it's fantastic to see that their \n",
        "hard work is paying off.\"\n",
        "\n",
        "The survey also revealed that the \n",
        "Social Security Administration had the lowest satisfaction \n",
        "rating, with only 45% of employees indicating they were \n",
        "satisfied with their job. The government has pledged to \n",
        "address the concerns raised by employees in the survey and \n",
        "work towards improving job satisfaction across all departments.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "aGpot4J_0hgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Infer Topics"
      ],
      "metadata": {
        "id": "ensFNfyfIsHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Determine five topics that are being discussed in the \\\n",
        "following text, which is delimited by triple backticks.\n",
        "\n",
        "Make each item one or two words long. \n",
        "\n",
        "Format your response as a python comma separated list named inferred_topic_list.\n",
        "\n",
        "Text sample: '''{story}'''\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ujh0siyzIl8t",
        "outputId": "ce2f9414-b689-4dd5-f8ea-5a38b7124d6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "government survey, public sector employees, job satisfaction, NASA, Social Security Administration\n",
            "\n",
            "inferred_topic_list = ['government survey', 'public sector employees', 'job satisfaction', 'NASA', 'Social Security Administration']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create an alert matching a topic"
      ],
      "metadata": {
        "id": "YWrvLfJEJyob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pre-define a topic list of interest\n",
        "defined_topic_list = ['nasa', 'local government', 'engineering', 'employee satisfaction', 'federal government']"
      ],
      "metadata": {
        "id": "HnSXiWwHJYmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "Determine whether each item in the following list of \\\n",
        "topics is a topic in the text below, which\n",
        "is delimited with triple backticks.\n",
        "\n",
        "Give your answer as list with 0 or 1 for each topic.\\\n",
        "\n",
        "List of topics: {\", \".join(defined_topic_list)}\n",
        "\n",
        "Text sample: '''{story}'''\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1jIB0_dKVHb",
        "outputId": "8dc6a19b-5bf9-4306-92a0-dca134943567"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nasa: 1\n",
            "local government: 0\n",
            "engineering: 0\n",
            "employee satisfaction: 1\n",
            "federal government: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# spit out an alert on topic matches\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Determine whether each item in the following list of \\\n",
        "topics is a topic in the text below, which\n",
        "is delimited with triple backticks.\n",
        "\n",
        "Give your answer as list of alerts as follows:\n",
        "\n",
        "For each matching topic, display \n",
        "  ALERT: matching topic STORY!\n",
        "\n",
        "List of topics: {\", \".join(defined_topic_list)}\n",
        "\n",
        "Text sample: '''{story}'''\n",
        "\"\"\"\n",
        "response = get_completion(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpdQkfXyKjHE",
        "outputId": "24a40c7b-4ff8-4ad3-afe8-32890672f3be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ALERT: matching topic NASA! \n",
            "\n",
            "ALERT: matching topic federal government! \n",
            "\n",
            "ALERT: matching topic employee satisfaction! \n",
            "\n",
            "Note: The text mentions local government indirectly through the survey conducted by the government, but it is not a main topic. Similarly, engineering is not mentioned in the text.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Lqt2tVmLdVi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}